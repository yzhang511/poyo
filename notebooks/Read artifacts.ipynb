{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading models from checkpoints demo\n",
    "\n",
    "I have a local ckpt file, and I want to load it and run inference on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[14:38:21] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"color: #df6da9; text-decoration-color: #df6da9; font-weight: bold\">(੭｡╹▿╹｡)੭</span> Poyo!                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[14:38:21]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1;38;2;223;109;169m(\u001b[0m\u001b[1;38;2;223;109;169m੭｡╹▿╹｡\u001b[0m\u001b[1;38;2;223;109;169m)\u001b[0m\u001b[1;38;2;223;109;169m੭\u001b[0m Poyo!                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[14:38:24] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Created a temporary directory at <span style=\"color: #800080; text-decoration-color: #800080\">/tmp/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">tmpbc1inpkl</span>                                              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[14:38:24]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Created a temporary directory at \u001b[35m/tmp/\u001b[0m\u001b[95mtmpbc1inpkl\u001b[0m                                              \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Writing <span style=\"color: #800080; text-decoration-color: #800080\">/tmp/tmpbc1inpkl/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">_remote_module_non_scriptable.py</span>                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Writing \u001b[35m/tmp/tmpbc1inpkl/\u001b[0m\u001b[95m_remote_module_non_scriptable.py\u001b[0m                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[14:38:30] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> xformers not installed. Won't use memory-efficient attention.                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[14:38:30]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m xformers not installed. Won't use memory-efficient attention.                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/p/patrick.mineault/.conda/envs/poyo/lib/python3.9/site-packages/lightning/pytorch/utilities/parsing.py:196: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "from kirby.utils.train_wrapper import TrainWrapper\n",
    "wrapper = TrainWrapper.load_from_checkpoint(\"../scripts/logs/lightning_logs/version_30/checkpoints/last.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerceiverNM(\n",
       "  (unit_emb): Embedding(226, 64)\n",
       "  (spike_type_emb): Embedding(4, 64)\n",
       "  (task_emb): Embedding(64, 64)\n",
       "  (latent_emb): Embedding(16, 64)\n",
       "  (rotary_emb): RotaryEmbedding()\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       "  (enc_atn): RotaryCrossAttention(\n",
       "    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm_context): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (to_q): Linear(in_features=64, out_features=128, bias=False)\n",
       "    (to_kv): Linear(in_features=64, out_features=256, bias=False)\n",
       "    (to_out): Linear(in_features=128, out_features=64, bias=True)\n",
       "  )\n",
       "  (enc_ffn): Sequential(\n",
       "    (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): FeedForward(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=512, bias=True)\n",
       "        (1): GEGLU()\n",
       "        (2): Dropout(p=0.2, inplace=False)\n",
       "        (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (proc_layers): ModuleList(\n",
       "    (0-11): 12 x ModuleList(\n",
       "      (0): RotarySelfAttention(\n",
       "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (to_qkv): Linear(in_features=64, out_features=1536, bias=False)\n",
       "        (to_out): Linear(in_features=512, out_features=64, bias=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=512, bias=True)\n",
       "            (1): GEGLU()\n",
       "            (2): Dropout(p=0.2, inplace=False)\n",
       "            (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dec_atn): RotaryCrossAttention(\n",
       "    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm_context): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (to_q): Linear(in_features=64, out_features=128, bias=False)\n",
       "    (to_kv): Linear(in_features=64, out_features=256, bias=False)\n",
       "    (to_out): Linear(in_features=128, out_features=64, bias=True)\n",
       "  )\n",
       "  (dec_ffn): Sequential(\n",
       "    (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): FeedForward(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=512, bias=True)\n",
       "        (1): GEGLU()\n",
       "        (2): Dropout(p=0.2, inplace=False)\n",
       "        (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder_out): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9622, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.model.dec_ffn[0].weight.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9622, device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "ckpt_raw = torch.load(\"../scripts/logs/lightning_logs/version_30/checkpoints/last.ckpt\")\n",
    "ckpt_raw['state_dict'][\"model.dec_ffn.0.weight\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load from wandb\n",
    "\n",
    "I've uploaded the checkpoint to wandb via:\n",
    "\n",
    "```wandb artifact put logs/lightning_logs/version_30/checkpoints/last.ckpt -t model -n single_session```\n",
    "\n",
    "Instantiate this model from the cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1bgi9owu) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ruby-breeze-18</strong> at: <a href='https://wandb.ai/neuro-galaxy/poyo/runs/1bgi9owu' target=\"_blank\">https://wandb.ai/neuro-galaxy/poyo/runs/1bgi9owu</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230726_145621-1bgi9owu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1bgi9owu). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mila/p/patrick.mineault/Documents/project-kirby/notebooks/wandb/run-20230726_145711-o4zok5id</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/neuro-galaxy/poyo/runs/o4zok5id' target=\"_blank\">solar-spaceship-19</a></strong> to <a href='https://wandb.ai/neuro-galaxy/poyo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/neuro-galaxy/poyo' target=\"_blank\">https://wandb.ai/neuro-galaxy/poyo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/neuro-galaxy/poyo/runs/o4zok5id' target=\"_blank\">https://wandb.ai/neuro-galaxy/poyo/runs/o4zok5id</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "run = wandb.init(project=\"poyo\", entity=\"neuro-galaxy\", )\n",
    "\n",
    "artifact = run.use_artifact(\"neuro-galaxy/poyo/single_session:latest\")\n",
    "path = artifact.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is downloaded, we can easily recover it using the same mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/p/patrick.mineault/.conda/envs/poyo/lib/python3.9/site-packages/lightning/pytorch/utilities/parsing.py:196: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "wrapper_cloud = TrainWrapper.load_from_checkpoint(f\"{path}/last.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerceiverNM(\n",
       "  (unit_emb): Embedding(226, 64)\n",
       "  (spike_type_emb): Embedding(4, 64)\n",
       "  (task_emb): Embedding(64, 64)\n",
       "  (latent_emb): Embedding(16, 64)\n",
       "  (rotary_emb): RotaryEmbedding()\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       "  (enc_atn): RotaryCrossAttention(\n",
       "    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm_context): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (to_q): Linear(in_features=64, out_features=128, bias=False)\n",
       "    (to_kv): Linear(in_features=64, out_features=256, bias=False)\n",
       "    (to_out): Linear(in_features=128, out_features=64, bias=True)\n",
       "  )\n",
       "  (enc_ffn): Sequential(\n",
       "    (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): FeedForward(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=512, bias=True)\n",
       "        (1): GEGLU()\n",
       "        (2): Dropout(p=0.2, inplace=False)\n",
       "        (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (proc_layers): ModuleList(\n",
       "    (0-11): 12 x ModuleList(\n",
       "      (0): RotarySelfAttention(\n",
       "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (to_qkv): Linear(in_features=64, out_features=1536, bias=False)\n",
       "        (to_out): Linear(in_features=512, out_features=64, bias=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=512, bias=True)\n",
       "            (1): GEGLU()\n",
       "            (2): Dropout(p=0.2, inplace=False)\n",
       "            (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dec_atn): RotaryCrossAttention(\n",
       "    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm_context): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (to_q): Linear(in_features=64, out_features=128, bias=False)\n",
       "    (to_kv): Linear(in_features=64, out_features=256, bias=False)\n",
       "    (to_out): Linear(in_features=128, out_features=64, bias=True)\n",
       "  )\n",
       "  (dec_ffn): Sequential(\n",
       "    (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): FeedForward(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=512, bias=True)\n",
       "        (1): GEGLU()\n",
       "        (2): Dropout(p=0.2, inplace=False)\n",
       "        (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder_out): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper_cloud.model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poyo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
