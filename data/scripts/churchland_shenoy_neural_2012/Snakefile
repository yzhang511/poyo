######################################################
# Churchland & Shenoy (2012)
######################################################

DATASET = "churchland_shenoy_neural_2012"
DANDI_ID = "000070"

RAW_DIR = config["RAW_DIR"]
PROCESSED_DIR = config["PROCESSED_DIR"]
COMPRESSED_DIR = config["COMPRESSED_DIR"]

DATASETS = [
    "sub-Jenkins/sub-Jenkins_ses-20090912",
    "sub-Jenkins/sub-Jenkins_ses-20090916",
    "sub-Jenkins/sub-Jenkins_ses-20090918",
    "sub-Jenkins/sub-Jenkins_ses-20090923",
    "sub-Nitschke/sub-Nitschke_ses-20090812",
    "sub-Nitschke/sub-Nitschke_ses-20090819",
    "sub-Nitschke/sub-Nitschke_ses-20090910",
    "sub-Nitschke/sub-Nitschke_ses-20090920",
    "sub-Nitschke/sub-Nitschke_ses-20090922",
    ]

rule all:
    input:
        f"{PROCESSED_DIR}/{DATASET}/description.mpk"
        # nwb_files = expand(f"{RAW_DIR}/{DATASET}/{DANDI_ID}/{{dataset}}_behavior+ecephys.nwb", dataset=DATASETS)
        # 

rule download_dataset:
    output:
        nwb_files = expand(f"{RAW_DIR}/{DATASET}/{DANDI_ID}/{{dataset}}_behavior+ecephys.nwb", dataset=DATASETS)
    shell:
        f"""
        mkdir -p {RAW_DIR}/{DATASET}
        dandi download -o {RAW_DIR}/{DATASET} -e refresh https://dandiarchive.org/dandiset/000070/draft
        """

rule prepare_data:
    input:
        py_script = f"data/scripts/{DATASET}/prepare_data.py",
        nwb_files = expand(f"{RAW_DIR}/{DATASET}/{DANDI_ID}/{{dataset}}_behavior+ecephys.nwb", dataset=DATASETS)
    output:
        description = f"{PROCESSED_DIR}/{DATASET}/description.mpk"
    shell:
        f"""
        mkdir -p {PROCESSED_DIR}/{DATASET}
        python data/scripts/{DATASET}/prepare_data.py --input_dir {RAW_DIR}/{DATASET} --output_dir {PROCESSED_DIR}/{DATASET}
        """

include: "../freeze.smk"