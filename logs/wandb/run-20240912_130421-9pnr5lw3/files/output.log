Wandb ID: 9pnr5lw3
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[2024-09-12 13:04:22,627][__main__][INFO] - Local rank/node rank/world size/num nodes: 0/0/1/1
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 1 processes
----------------------------------------------------------------------------------------------------

LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name                 | Type                   | Params
----------------------------------------------------------------
0 | model                | POYOPlus               | 1.3 M
1 | model.unit_emb       | InfiniteVocabEmbedding | 11.8 K
2 | model.session_emb    | InfiniteVocabEmbedding | 128
3 | model.spike_type_emb | Embedding              | 256
4 | model.task_emb       | Embedding              | 2.0 K
5 | model.latent_emb     | Embedding              | 1.0 K
6 | model.perceiver_io   | PerceiverRotary        | 1.3 M
7 | model.readout        | MultitaskReadout       | 68.6 K
----------------------------------------------------------------
1.3 M     Trainable params
0         Non-trainable params
1.3 M     Total params
5.346     Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/home/yzhang39/miniconda3/envs/poyo/lib/python3.8/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Training: 0it [00:00, ?it/s][2024-09-12 13:04:33,996][root][INFO] - Memory info:
MemTotal:       394805416 kB
MemFree:        209912448 kB
MemAvailable:   380259972 kB
Buffers:          284164 kB
Cached:         172074128 kB
SwapCached:            0 kB
Active:         66235260 kB
Inactive:       113984348 kB
Active(anon):       1164 kB
Inactive(anon):  8113352 kB
Active(file):   66234096 kB
Inactive(file): 105870996 kB
Unevictable:           0 kB
Mlocked:               0 kB
SwapTotal:             0 kB
SwapFree:              0 kB
Dirty:              4660 kB
Writeback:             8 kB
AnonPages:       7810520 kB
Mapped:          3433100 kB
Shmem:            253260 kB
KReclaimable:    1393456 kB
Slab:            2795644 kB
SReclaimable:    1393456 kB
SUnreclaim:      1402188 kB
KernelStack:       23552 kB
PageTables:        50772 kB
NFS_Unstable:          0 kB
Bounce:                0 kB
WritebackTmp:          0 kB
CommitLimit:    197402708 kB
Committed_AS:   12107600 kB
VmallocTotal:   34359738367 kB
VmallocUsed:      427264 kB
VmallocChunk:          0 kB
Percpu:           161280 kB
HardwareCorrupted:     0 kB
AnonHugePages:   5707776 kB
ShmemHugePages:        0 kB
ShmemPmdMapped:        0 kB
FileHugePages:         0 kB
FilePmdMapped:         0 kB
HugePages_Total:       0
HugePages_Free:        0
HugePages_Rsvd:        0
HugePages_Surp:        0
Hugepagesize:       2048 kB
Hugetlb:               0 kB
DirectMap4k:    18481516 kB
DirectMap2M:    377487360 kB
DirectMap1G:     7340032 kB

Epoch 0:   0%|                                                           | 0/1 [00:00<?, ?it/s]
/home/yzhang39/miniconda3/envs/poyo/lib/python3.8/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Error executing job with overrides: []
Traceback (most recent call last):
  File "train.py", line 276, in main
    run_training(cfg)
  File "train.py", line 261, in run_training
    trainer.fit(
  File "/home/yzhang39/miniconda3/envs/poyo/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py", line 532, in fit
    call._call_and_handle_interrupt(
  File "/home/yzhang39/miniconda3/envs/poyo/lib/python3.8/site-packages/lightning/pytorch/trainer/call.py", line 42, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/yzhang39/miniconda3/envs/poyo/lib/python3.8/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 93, in launch
    return function(*args, **kwargs)
  File "/home/yzhang39/miniconda3/envs/poyo/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py", line 571, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/yzhang39/miniconda3/envs/poyo/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py", line 980, in _run
    results = self._run_stage()
  File "/home/yzhang39/miniconda3/envs/poyo/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py", line 1023, in _run_stage
    self.fit_loop.run()
  File "/home/yzhang39/miniconda3/envs/poyo/lib/python3.8/site-packages/lightning/pytorch/loops/fit_loop.py", line 202, in run
    self.advance()
  File "/home/yzhang39/miniconda3/envs/poyo/lib/python3.8/site-packages/lightning/pytorch/loops/fit_loop.py", line 355, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/yzhang39/miniconda3/envs/poyo/lib/python3.8/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "/home/yzhang39/miniconda3/envs/poyo/lib/python3.8/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 190, in advance
    batch = next(data_fetcher)
  File "/home/yzhang39/miniconda3/envs/poyo/lib/python3.8/site-packages/lightning/pytorch/loops/fetchers.py", line 126, in __next__
    batch = super().__next__()
  File "/home/yzhang39/miniconda3/envs/poyo/lib/python3.8/site-packages/lightning/pytorch/loops/fetchers.py", line 58, in __next__
    batch = next(iterator)
  File "/home/yzhang39/miniconda3/envs/poyo/lib/python3.8/site-packages/lightning/pytorch/utilities/combined_loader.py", line 285, in __next__
    out = next(self._iterator)
  File "/home/yzhang39/miniconda3/envs/poyo/lib/python3.8/site-packages/lightning/pytorch/utilities/combined_loader.py", line 65, in __next__
    out[i] = next(self.iterators[i])
  File "/home/yzhang39/miniconda3/envs/poyo/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/yzhang39/miniconda3/envs/poyo/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/home/yzhang39/miniconda3/envs/poyo/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/home/yzhang39/miniconda3/envs/poyo/lib/python3.8/site-packages/torch/_utils.py", line 722, in reraise
    raise exception
TypeError: Caught TypeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/yzhang39/miniconda3/envs/poyo/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/yzhang39/miniconda3/envs/poyo/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/yzhang39/miniconda3/envs/poyo/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/yzhang39/project-kirby/kirby/data/dataset.py", line 428, in __getitem__
    sample = self.transform(sample)
  File "/home/yzhang39/project-kirby/kirby/transforms/container.py", line 22, in __call__
    data = transform(data)
  File "/home/yzhang39/project-kirby/kirby/models/poyo_plus.py", line 263, in __call__
    ) = prepare_for_multitask_readout(
  File "/home/yzhang39/project-kirby/kirby/nn/multitask_readout.py", line 162, in prepare_for_multitask_readout
    decoder = decoder_registry[key].__dict__ | decoder  # config overrides registry
TypeError: unsupported operand type(s) for |: 'dict' and 'dict'


Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
